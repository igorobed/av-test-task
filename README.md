# av-test-task
My solution of test task for AVSoft

### Ход решения:
data_exploration.ipynb -> baseline.ipynb -> embs_exploration.ipynb -> best_solution.ipynb

### Результаты:
Наилучшим подходом в данный момент себя показало кодирование имени репозитория, используя One-Hot Encoder, деление на 3 группы авторов комммитов по числу найденных ими ошибок и кодирование их также с помощью One-Hot Encoder. Была подтверждена гипотеза, что, учитывая смысл(хотя бы частичный) сообщения коммита, можно лучше предсказывать число найденных багов. Время коммита было преобразовано в пару полезных признаков: рабочее-нерабочее время, рабочий-выходной день недели. Я испытал как TfidfVectorizer, так и предобученную мультиязыковую модель на основе Transformer и CNN для получения эмбеддинга предложения. Второй вариант дал гораздо более сильное уменьшение средней квадратичной ошибки. Были испробованы TruncatedSVD и PCA, так как данных очень мало, а размер получаемого вектора признаков для объекта превышает общее количество объектов в имеющемся датасете. Однако, данные подходы не показали сколько-нибудь значительного улучшения качества работы модели.

Лучше всего себя на данный момент показала двухслойная нейронная сеть с функцийе активации Relu. Ее mse на кросс-валидации составило 1.0978673099828316, а коэффициент детерминации - 0.663177781335307

Дальнейшая работа:

1. Обучить двух(трех)слойную нейронную сеть с помощью фрэймворка Pytorch с использованием слоя Embeddings для категориальных переменных, таких как имя репозитория, имя автора коммита, рабочее время, будний день недели.

2. Попробовать применить стэкинг

3. Подумать над тем, какие еще признаки можно сгенерировать вручную на основе времени коммита и текста сообщения коммита.

4. Попробовать подобрать параметры для моделей из специализированных библиотек для градиентного бустинга(lightgbm и catboost)
