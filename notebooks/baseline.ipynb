{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.data_utils as d_u\n",
    "import src.feats_generation as f_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предварительный анализ данных производится в файле data_exploration.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим исходный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/АВСОФТ_тест_ML_приложение.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['repository_name', 'commit_hash', 'commit_date', 'commit_author',\n",
       "       'commit_message', 'bugs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим столбец, не несущий никакой полезной инфы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"commit_hash\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем категориальные признаки в числовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE для имени репозитория\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(df.repository_name)], axis=1)\n",
    "df.drop(columns=[\"repository_name\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# закодируем столбец commit_author, в данном случае я сделаю обычный OHE\n",
    "\n",
    "df = f_g.ohe(df, \"commit_author\")  # функция выполняет действия аналогичные ячейке выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_date</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>bugs</th>\n",
       "      <th>agent</th>\n",
       "      <th>conductor</th>\n",
       "      <th>dockers</th>\n",
       "      <th>mlm</th>\n",
       "      <th>sensor</th>\n",
       "      <th>standard</th>\n",
       "      <th>Alice</th>\n",
       "      <th>Bob</th>\n",
       "      <th>Carol</th>\n",
       "      <th>Dabe</th>\n",
       "      <th>Eve</th>\n",
       "      <th>Mallory</th>\n",
       "      <th>Peggy</th>\n",
       "      <th>Trudy</th>\n",
       "      <th>Victor</th>\n",
       "      <th>Wendy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>2020-04-13T12:05:28</td>\n",
       "      <td>insults.dataReceived(): file head/tail problem...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2020-06-11T10:47:25</td>\n",
       "      <td>fix turnoff filebeat</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2020-04-08T15:47:05</td>\n",
       "      <td>reduce image dns and kako image sizes</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             commit_date                                     commit_message  \\\n",
       "215  2020-04-13T12:05:28  insults.dataReceived(): file head/tail problem...   \n",
       "86   2020-06-11T10:47:25                               fix turnoff filebeat   \n",
       "284  2020-04-08T15:47:05              reduce image dns and kako image sizes   \n",
       "\n",
       "     bugs  agent  conductor  dockers  mlm  sensor  standard  Alice  Bob  \\\n",
       "215     3      0          0        1    0       0         0      0    1   \n",
       "86      2      0          1        0    0       0         0      0    0   \n",
       "284     4      0          0        0    0       1         0      0    0   \n",
       "\n",
       "     Carol  Dabe  Eve  Mallory  Peggy  Trudy  Victor  Wendy  \n",
       "215      0     0    0        0      0      0       0      0  \n",
       "86       0     0    0        0      0      0       0      1  \n",
       "284      0     0    0        1      0      0       0      0  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# данные на текущий момент\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем признаки из столбца отвечающего за время коммита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# так как изначально тип данного столбца - object\n",
    "df[\"commit_date\"] = pd.to_datetime(df.commit_date)\n",
    "\n",
    "df = f_g.encode_work_days(df)\n",
    "df = f_g.encode_work_hours(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_date</th>\n",
       "      <th>commit_message</th>\n",
       "      <th>bugs</th>\n",
       "      <th>agent</th>\n",
       "      <th>conductor</th>\n",
       "      <th>dockers</th>\n",
       "      <th>mlm</th>\n",
       "      <th>sensor</th>\n",
       "      <th>standard</th>\n",
       "      <th>Alice</th>\n",
       "      <th>...</th>\n",
       "      <th>Eve</th>\n",
       "      <th>Mallory</th>\n",
       "      <th>Peggy</th>\n",
       "      <th>Trudy</th>\n",
       "      <th>Victor</th>\n",
       "      <th>Wendy</th>\n",
       "      <th>no_work_d</th>\n",
       "      <th>work_d</th>\n",
       "      <th>no_work_h</th>\n",
       "      <th>work_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>2020-05-01 11:48:58</td>\n",
       "      <td>add athena.rule</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2020-05-13 16:35:53</td>\n",
       "      <td>testing/trapped_files</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2020-06-10 10:16:27</td>\n",
       "      <td>add log cleaner</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            commit_date         commit_message  bugs  agent  conductor  \\\n",
       "241 2020-05-01 11:48:58        add athena.rule     1      0          0   \n",
       "52  2020-05-13 16:35:53  testing/trapped_files     1      0          0   \n",
       "89  2020-06-10 10:16:27        add log cleaner     2      0          1   \n",
       "\n",
       "     dockers  mlm  sensor  standard  Alice  ...  Eve  Mallory  Peggy  Trudy  \\\n",
       "241        0    0       1         0      0  ...    0        0      0      0   \n",
       "52         0    0       0         1      0  ...    0        0      0      0   \n",
       "89         0    0       0         0      0  ...    0        0      0      0   \n",
       "\n",
       "     Victor  Wendy  no_work_d  work_d  no_work_h  work_h  \n",
       "241       0      1          0       1          0       1  \n",
       "52        1      0          0       1          0       1  \n",
       "89        0      1          0       1          0       1  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"commit_date\" in df.columns:\n",
    "    df.drop(columns=[\"commit_date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала получим бэйзлан без какой-либо информации из сообщения коммита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_msg = df.drop(columns=[\"commit_message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_without_msg.drop(columns=[\"bugs\"])\n",
    "y = df_without_msg.bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_idxs, test_idxs = X_train.index, X_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отмасштабируем значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим качество на разных базовых моделях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - LinearRegression()\n",
      "Среднее квадратное отклонение: 3.599230424388977\n",
      "\n",
      "Модель - SGDRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 2.792461669579143\n",
      "\n",
      "Модель - Ridge(random_state=42)\n",
      "Среднее квадратное отклонение: 2.813940971574099\n",
      "\n",
      "Модель - Lasso(random_state=42)\n",
      "Среднее квадратное отклонение: 2.5254327662437523\n",
      "\n",
      "Модель - RandomForestRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 2.6581221678556193\n",
      "\n",
      "Модель - GradientBoostingRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 2.7976837028211925\n",
      "\n",
      "Модель - SVR()\n",
      "Среднее квадратное отклонение: 2.547624178147599\n",
      "\n",
      "Модель - MLPRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 2.864029183479513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zoo_models = [\n",
    "    LinearRegression(),\n",
    "    SGDRegressor(random_state=42),\n",
    "    Ridge(random_state=42),\n",
    "    Lasso(random_state=42),\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    SVR(),\n",
    "    MLPRegressor(random_state=42)\n",
    "    ]\n",
    "\n",
    "for model in zoo_models:\n",
    "    print(f\"Модель - {model}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print(f\"Среднее квадратное отклонение: {mean_squared_error(y_test, preds)}\")\n",
    "    # print(f\"Среднее абсолютное отклонение: {mean_absolute_error(y_test, preds)}\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим качество на кросс-валидации для каждой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - LinearRegression()\n",
      "Среднее квадратное отклонение: 3.061867391378663\n",
      "\n",
      "Модель - SGDRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 2.8427464535834384\n",
      "\n",
      "Модель - Ridge(random_state=42)\n",
      "Среднее квадратное отклонение: 2.8261025740434538\n",
      "\n",
      "Модель - Lasso(random_state=42)\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "\n",
      "Модель - RandomForestRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 2.8155012197320235\n",
      "\n",
      "Модель - GradientBoostingRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 2.8420382249740155\n",
      "\n",
      "Модель - SVR()\n",
      "Среднее квадратное отклонение: 3.0814115021828874\n",
      "\n",
      "Модель - MLPRegressor(random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DungeonMaster3000\\.conda\\envs\\avsoft_test_task\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее квадратное отклонение: 2.8306670706008417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "splits = cv.split(X)\n",
    "\n",
    "eval_data_lst = []\n",
    "for i_train, i_test in splits:\n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = X.loc[i_train], X.loc[i_test], y[i_train], y[i_test]\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train)\n",
    "    X_test = ss.transform(X_test)\n",
    "\n",
    "    eval_data_lst.append((X_train, X_test, y_train, y_test))\n",
    "\n",
    "for model in zoo_models:\n",
    "    print(f\"Модель - {model}\")\n",
    "\n",
    "    tmp_lst = []\n",
    "\n",
    "    for X_train, X_test, y_train, y_test in eval_data_lst:\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        tmp_lst.append(mean_squared_error(y_test, preds))\n",
    "    print(f\"Среднее квадратное отклонение: {np.mean(tmp_lst)}\")\n",
    "    # print(f\"Среднее абсолютное отклонение: {mean_absolute_error(y_test, preds)}\")\n",
    "    print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим, как отработают модели, если мы попробуем извлечь информацию из сообщения комита самым простым способом с помощью tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 555)\n",
      "(64, 555)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=d_u.simple_tokenizer)\n",
    "\n",
    "msg_embs_train = tfidf.fit_transform(df.commit_message.values[train_idxs]).toarray()\n",
    "msg_embs_test = tfidf.transform(df.commit_message.values[test_idxs]).toarray()\n",
    "print(msg_embs_train.shape)\n",
    "print(msg_embs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"bugs\", \"commit_message\"])\n",
    "y = df.bugs\n",
    "\n",
    "msg_embs_train = pd.DataFrame(msg_embs_train)\n",
    "msg_embs_test = pd.DataFrame(msg_embs_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X.loc[train_idxs], X.loc[test_idxs], y[train_idxs], y[test_idxs]\n",
    "\n",
    "msg_embs_train.index = train_idxs\n",
    "msg_embs_test.index = test_idxs\n",
    "\n",
    "X_train_emb = pd.concat([X_train, msg_embs_train], axis=1)\n",
    "X_test_emb = pd.concat([X_test, msg_embs_test], axis=1)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_emb = ss.fit_transform(X_train_emb.to_numpy())\n",
    "X_test_emb = ss.transform(X_test_emb.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - LinearRegression()\n",
      "Среднее квадратное отклонение: 4.321412563493218\n",
      "\n",
      "Модель - SGDRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 46157.15314686576\n",
      "\n",
      "Модель - Ridge(random_state=42)\n",
      "Среднее квадратное отклонение: 3.4468280846426103\n",
      "\n",
      "Модель - Lasso(random_state=42)\n",
      "Среднее квадратное отклонение: 2.5254327662437523\n",
      "\n",
      "Модель - RandomForestRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 1.9212890625\n",
      "\n",
      "Модель - GradientBoostingRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 1.9642904281494462\n",
      "\n",
      "Модель - SVR()\n",
      "Среднее квадратное отклонение: 3.239512981053275\n",
      "\n",
      "Модель - MLPRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 3.4272161989544205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in zoo_models:\n",
    "    print(f\"Модель - {model}\")\n",
    "    model.fit(X_train_emb, y_train)\n",
    "    preds = model.predict(X_test_emb)\n",
    "    print(f\"Среднее квадратное отклонение: {mean_squared_error(y_test, preds)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем заметить, что при добавлении информации из сообщения коммита с помощью tfidf мы получили наименьшее отклонение от целевой переменной с помощью моделей RandomForestRegressor и GradientBoostingRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для чистоты эксперимента будем создавать tfidf только на основе трэина на каждом разбиении при кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "splits = cv.split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_lst = []  # список содержащий трэин и тест для каждого разбиения\n",
    "for i_train, i_test in splits:\n",
    "    tfidf = TfidfVectorizer(tokenizer=d_u.simple_tokenizer)\n",
    "\n",
    "    msg_embs_train = tfidf.fit_transform(df.commit_message.values[i_train]).toarray()\n",
    "    msg_embs_test = tfidf.transform(df.commit_message.values[i_test]).toarray()\n",
    "\n",
    "    msg_embs_train = pd.DataFrame(msg_embs_train)\n",
    "    msg_embs_test = pd.DataFrame(msg_embs_test)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = X.loc[i_train], X.loc[i_test], y[i_train], y[i_test]\n",
    "\n",
    "    msg_embs_train.index = i_train\n",
    "    msg_embs_test.index = i_test\n",
    "\n",
    "    X_train_emb = pd.concat([X_train, msg_embs_train], axis=1)\n",
    "    X_test_emb = pd.concat([X_test, msg_embs_test], axis=1)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    X_train_emb = ss.fit_transform(X_train_emb.to_numpy())\n",
    "    X_test_emb = ss.transform(X_test_emb.to_numpy())\n",
    "\n",
    "    # X_train_emb = X_train_emb.to_numpy()\n",
    "    # X_test_emb = X_test_emb.to_numpy()\n",
    "\n",
    "    eval_data_lst.append((X_train_emb, X_test_emb, y_train, y_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - LinearRegression()\n",
      "Среднее квадратное отклонение: 3.840936851252214\n",
      "________________________________________________\n",
      "Модель - SGDRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 66171.03174002295\n",
      "________________________________________________\n",
      "Модель - Ridge(random_state=42)\n",
      "Среднее квадратное отклонение: 3.5483044505545527\n",
      "________________________________________________\n",
      "Модель - Lasso(random_state=42)\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "________________________________________________\n",
      "Модель - RandomForestRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 2.55626306547619\n",
      "________________________________________________\n",
      "Модель - GradientBoostingRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 2.3125281732052922\n",
      "________________________________________________\n",
      "Модель - SVR()\n",
      "Среднее квадратное отклонение: 3.92950610268129\n",
      "________________________________________________\n",
      "Модель - MLPRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 4.642283493589365\n",
      "________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for model in zoo_models:\n",
    "    print(f\"Модель - {model}\")\n",
    "\n",
    "    tmp_lst = []\n",
    "\n",
    "    for X_train_emb, X_test_emb, y_train, y_test in eval_data_lst:\n",
    "        model.fit(X_train_emb, y_train)\n",
    "        preds = model.predict(X_test_emb)\n",
    "        tmp_lst.append(mean_squared_error(y_test, preds))\n",
    "    print(f\"Среднее квадратное отклонение: {np.mean(tmp_lst)}\")\n",
    "    # print(f\"Среднее абсолютное отклонение: {mean_absolute_error(y_test, preds)}\")\n",
    "    print(\"________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее качество получается на моделях RandomForestRegressor и GradientBoostingRegressor. Попробуем то же самое, но без использования StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - LinearRegression()\n",
      "Среднее квадратное отклонение: 4.051258697962091\n",
      "________________________________________________\n",
      "Модель - SGDRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 2.544314136103807\n",
      "________________________________________________\n",
      "Модель - Ridge(random_state=42)\n",
      "Среднее квадратное отклонение: 2.569979525885581\n",
      "________________________________________________\n",
      "Модель - Lasso(random_state=42)\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "________________________________________________\n",
      "Модель - RandomForestRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 2.55626306547619\n",
      "________________________________________________\n",
      "Модель - GradientBoostingRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 2.3125281732052922\n",
      "________________________________________________\n",
      "Модель - SVR()\n",
      "Среднее квадратное отклонение: 2.75252931290019\n",
      "________________________________________________\n",
      "Модель - MLPRegressor(random_state=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DungeonMaster3000\\.conda\\envs\\avsoft_test_task\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DungeonMaster3000\\.conda\\envs\\avsoft_test_task\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DungeonMaster3000\\.conda\\envs\\avsoft_test_task\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DungeonMaster3000\\.conda\\envs\\avsoft_test_task\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее квадратное отклонение: 2.7325733258057694\n",
      "________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DungeonMaster3000\\.conda\\envs\\avsoft_test_task\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "splits = cv.split(X)\n",
    "\n",
    "eval_data_lst = []  # список содержащий трэин и тест для каждого разбиения\n",
    "for i_train, i_test in splits:\n",
    "    tfidf = TfidfVectorizer(tokenizer=d_u.simple_tokenizer)\n",
    "\n",
    "    msg_embs_train = tfidf.fit_transform(df.commit_message.values[i_train]).toarray()\n",
    "    msg_embs_test = tfidf.transform(df.commit_message.values[i_test]).toarray()\n",
    "\n",
    "    msg_embs_train = pd.DataFrame(msg_embs_train)\n",
    "    msg_embs_test = pd.DataFrame(msg_embs_test)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = X.loc[i_train], X.loc[i_test], y[i_train], y[i_test]\n",
    "\n",
    "    msg_embs_train.index = i_train\n",
    "    msg_embs_test.index = i_test\n",
    "\n",
    "    X_train_emb = pd.concat([X_train, msg_embs_train], axis=1)\n",
    "    X_test_emb = pd.concat([X_test, msg_embs_test], axis=1)\n",
    "\n",
    "    X_train_emb = X_train_emb.to_numpy()\n",
    "    X_test_emb = X_test_emb.to_numpy()\n",
    "\n",
    "    eval_data_lst.append((X_train_emb, X_test_emb, y_train, y_test))   \n",
    "\n",
    "for model in zoo_models:\n",
    "    print(f\"Модель - {model}\")\n",
    "\n",
    "    tmp_lst = []\n",
    "\n",
    "    for X_train_emb, X_test_emb, y_train, y_test in eval_data_lst:\n",
    "        model.fit(X_train_emb, y_train)\n",
    "        preds = model.predict(X_test_emb)\n",
    "        tmp_lst.append(mean_squared_error(y_test, preds))\n",
    "    print(f\"Среднее квадратное отклонение: {np.mean(tmp_lst)}\")\n",
    "    # print(f\"Среднее абсолютное отклонение: {mean_absolute_error(y_test, preds)}\")\n",
    "    print(\"________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На кросс-валидации также видно, что при использование tfidf уменьшается среднее квадратичное отклоанение, причем если не проводить масштабирование, то в лидеры помимо моделей RandomForestRegressor и GradientBoostingRegreessor попадают и модели SGDRegressor и Ridge. Также имеет смысл поэксперементировать с архитектурой MLPRegressor и увеличением числа итераций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент лучшее значение на mse - 2.3125281732052922, которое было получено с помощь GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('avsoft_test_task')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55b5977c218ce617a475901f98f0c5239dda01575bc0160c4b4058a44613146e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
