{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DungeonMaster3000\\.conda\\envs\\avsoft_test_task\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DungeonMaster3000\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.data_utils as d_u\n",
    "import src.feats_generation as f_g\n",
    "import src.eval_utils as e_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В файле baseline.ipynb было показано, что использование эмбеддинга для сообщения коммита позволяет увеличить точность моделей. Попробуем tfidf с уменьшением размерности, а также предобученный мультиязыковой кодировщик предложений на основе Transformer и CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет и предобработаем категориальные фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = d_u.get_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_message</th>\n",
       "      <th>bugs</th>\n",
       "      <th>agent</th>\n",
       "      <th>conductor</th>\n",
       "      <th>dockers</th>\n",
       "      <th>mlm</th>\n",
       "      <th>sensor</th>\n",
       "      <th>standard</th>\n",
       "      <th>Alice</th>\n",
       "      <th>Bob</th>\n",
       "      <th>...</th>\n",
       "      <th>Eve</th>\n",
       "      <th>Mallory</th>\n",
       "      <th>Peggy</th>\n",
       "      <th>Trudy</th>\n",
       "      <th>Victor</th>\n",
       "      <th>Wendy</th>\n",
       "      <th>no_work_d</th>\n",
       "      <th>work_d</th>\n",
       "      <th>no_work_h</th>\n",
       "      <th>work_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>compose configs moved to traps/docker</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Добавил скрипт для запуска контейнера</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>moved config files to /opt/avssoft/configs</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 commit_message  bugs  agent  conductor  \\\n",
       "135       compose configs moved to traps/docker     4      0          1   \n",
       "7         Добавил скрипт для запуска контейнера     4      0          0   \n",
       "280  moved config files to /opt/avssoft/configs     3      0          0   \n",
       "\n",
       "     dockers  mlm  sensor  standard  Alice  Bob  ...  Eve  Mallory  Peggy  \\\n",
       "135        0    0       0         0      0    0  ...    0        1      0   \n",
       "7          0    1       0         0      0    0  ...    0        0      0   \n",
       "280        0    0       1         0      0    0  ...    0        1      0   \n",
       "\n",
       "     Trudy  Victor  Wendy  no_work_d  work_d  no_work_h  work_h  \n",
       "135      0       0      0          0       1          0       1  \n",
       "7        0       1      0          0       1          0       1  \n",
       "280      0       0      0          0       1          0       1  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"commit_message\", \"bugs\"])\n",
    "y = df.bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала посмотрим результат модели с эмбеддингами сообщений, которые мы получаем с помощью предобученной мультиязыковой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_embs = f_g.pretrained_model_sentence_emb(df.commit_message.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_idxs, test_idxs = X_train.index, X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, msg_embs[train_idxs]), axis=1)\n",
    "X_test = np.concatenate((X_test, msg_embs[test_idxs]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - LinearRegression()\n",
      "MSE: 3.9255156937438884\n",
      "\n",
      "Модель - SGDRegressor(random_state=42)\n",
      "MSE: 1.5442650283714352\n",
      "\n",
      "Модель - Ridge(random_state=42)\n",
      "MSE: 1.3328333886580885\n",
      "\n",
      "Модель - Lasso(random_state=42)\n",
      "MSE: 2.5254327662437523\n",
      "\n",
      "Модель - RandomForestRegressor(random_state=42)\n",
      "MSE: 0.86288125\n",
      "\n",
      "Модель - GradientBoostingRegressor(random_state=42)\n",
      "MSE: 0.7879865467367375\n",
      "\n",
      "Модель - SVR()\n",
      "MSE: 2.155657021426432\n",
      "\n",
      "Модель - MLPRegressor(max_iter=100000, random_state=42)\n",
      "MSE: 1.7726122043258286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zoo_models = [\n",
    "    LinearRegression(),\n",
    "    SGDRegressor(random_state=42),\n",
    "    Ridge(random_state=42),\n",
    "    Lasso(random_state=42),\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    SVR(),\n",
    "    MLPRegressor(random_state=42, max_iter=100000)\n",
    "    ]\n",
    "\n",
    "for model in zoo_models:\n",
    "    print(f\"Модель - {model}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print(f\"MSE: {mean_squared_error(y_test, preds)}\")\n",
    "    # print(f\"Среднее абсолютное отклонение: {mean_absolute_error(y_test, preds)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу заметно улучшение качества при использовании предобученной модели для генерации эмбеддинга предложения по сравнению с tfidf на том же трэйне и тесте(см. baseline.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим среднюю квадратичную ошибку на кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - LinearRegression()\n",
      "MSE: 3.6631705664438847\n",
      "\n",
      "Модель - SGDRegressor(random_state=42)\n",
      "MSE: 1.5791955326983218\n",
      "\n",
      "Модель - Ridge(random_state=42)\n",
      "MSE: 1.3792463938249164\n",
      "\n",
      "Модель - Lasso(random_state=42)\n",
      "MSE: 3.4774931163795175\n",
      "\n",
      "Модель - RandomForestRegressor(random_state=42)\n",
      "MSE: 1.7560374454365077\n",
      "\n",
      "Модель - GradientBoostingRegressor(random_state=42)\n",
      "MSE: 1.470161025026534\n",
      "\n",
      "Модель - SVR()\n",
      "MSE: 2.7170945885316122\n",
      "\n",
      "Модель - MLPRegressor(max_iter=100000, random_state=42)\n",
      "MSE: 1.4481975235824769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "ss = StandardScaler()\n",
    "X_eval = ss.fit_transform(X)\n",
    "X_eval = np.concatenate((X_eval, msg_embs), axis=1)\n",
    "\n",
    "for model in zoo_models:\n",
    "    print(f\"Модель - {model}\")\n",
    "    mse_mean = -np.mean(cross_val_score(model, X_eval, y, cv=cv, scoring=\"neg_mean_squared_error\"))\n",
    "    print(f\"MSE: {mse_mean}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от фиксированного трэйна и теста на кросс-валидации себя лучше всего показала линейная модель с L2 регуляризацией и однослойная нейронная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим, как понижение размерности эмбеддинга и применение StandardScaler влияет на качество "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала посмотрим на GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На оригинальных эмбеддингах\n",
      "-1 - 1.470161025026534\n",
      "На оригинальных эмбеддингах + масштабирование\n",
      "-1 - 1.470161025026534\n"
     ]
    }
   ],
   "source": [
    "print(\"На оригинальных эмбеддингах\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs)\n",
    "\n",
    "print(\"На оригинальных эмбеддингах + масштабирование\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С использованием PCA\n",
      "5 - 1.5173583599353186\n",
      "10 - 1.424636346846814\n",
      "15 - 1.486286074085759\n",
      "20 - 1.5754300114177344\n",
      "25 - 1.5040941687477412\n",
      "50 - 1.5894128842628683\n",
      "100 - 1.7054535460162703\n",
      "200 - 1.7929972103337974\n",
      "-1 - 1.470161025026534\n"
     ]
    }
   ],
   "source": [
    "print(\"С использованием PCA\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С использованием PCA + масштабироавние\n",
      "5 - 1.4887605803400457\n",
      "10 - 1.4686811725043527\n",
      "15 - 1.4882309726004117\n",
      "20 - 1.5340577496920773\n",
      "25 - 1.4795469969804564\n",
      "50 - 1.6390088703490686\n",
      "100 - 1.8527072529366666\n",
      "200 - 1.818254333906438\n",
      "-1 - 1.470161025026534\n"
     ]
    }
   ],
   "source": [
    "print(\"С использованием PCA + масштабироавние\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"pca\", scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С использованием SVD\n",
      "5 - 1.5585692467344392\n",
      "10 - 1.4375897036278857\n",
      "15 - 1.3885808583025905\n",
      "20 - 1.4035701591637975\n",
      "25 - 1.5666620261978133\n",
      "50 - 1.7105879995366127\n",
      "100 - 1.8202123338091556\n",
      "200 - 1.9189262797423408\n",
      "-1 - 1.470161025026534\n",
      "\n",
      "С использованием SVD + масштабирование\n",
      "5 - 1.4938899714482357\n",
      "10 - 1.5446139933213214\n",
      "15 - 1.5517560063622462\n",
      "20 - 1.3736620989400585\n",
      "25 - 1.5223086813647835\n",
      "50 - 1.5905919100962342\n",
      "100 - 1.8703566375404228\n",
      "200 - 1.9404148404118065\n",
      "-1 - 1.470161025026534\n"
     ]
    }
   ],
   "source": [
    "print(\"С использованием SVD\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"svd\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"С использованием SVD + масштабирование\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"svd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для базового градиентного бустинга лучший результат - 1.435900249421395 при понижении размерности эмбеддинга с помощью TruncatedSVD до 15 без применения масштабирования. Однако, если оставлять исходный размер эмбеддинга, то имеем mse - 1.470161025026534."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь протестируем понижение размерности с моделью Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge:\n",
      "\n",
      "На оригинальных эмбеддингах\n",
      "-1 - 1.3672444447352596\n",
      "\n",
      "На оригинальных эмбеддингах + масштабирование\n",
      "-1 - 1.3791697289464646\n",
      "\n",
      "С использованием PCA\n",
      "5 - 1.608595542403173\n",
      "10 - 1.5053366229869285\n",
      "15 - 1.4946788705669938\n",
      "20 - 1.5038457558324692\n",
      "25 - 1.5183192143949094\n",
      "50 - 1.4073004243768081\n",
      "100 - 1.3820707020223455\n",
      "200 - 1.3690134044912692\n",
      "-1 - 1.3672444447352596\n",
      "\n",
      "С использованием PCA + масштабироавние\n",
      "5 - 1.6132136939606194\n",
      "10 - 1.5086607226224173\n",
      "15 - 1.5005420626002066\n",
      "20 - 1.513415079915537\n",
      "25 - 1.5253903798315571\n",
      "50 - 1.411503149902688\n",
      "100 - 1.3955213867290475\n",
      "200 - 1.381822417802797\n",
      "-1 - 1.3791697289464646\n",
      "С использованием SVD\n",
      "5 - 1.71560445461086\n",
      "10 - 1.4789980076190083\n",
      "15 - 1.4589009634673815\n",
      "20 - 1.463223667172491\n",
      "25 - 1.4717254707227023\n",
      "50 - 1.4050965252565994\n",
      "100 - 1.3868345545166867\n",
      "200 - 1.3704707871867614\n",
      "-1 - 1.3672444447352596\n",
      "\n",
      "С использованием SVD + масштабирование\n",
      "5 - 1.7163396876275487\n",
      "10 - 1.4766688030250386\n",
      "15 - 1.4608633948782916\n",
      "20 - 1.4707248116881606\n",
      "25 - 1.4741424960626284\n",
      "50 - 1.4031645843362806\n",
      "100 - 1.3874891133654448\n",
      "200 - 1.3708767306783611\n",
      "-1 - 1.3672444447352596\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(random_state=42)\n",
    "\n",
    "print(\"Ridge:\\n\")\n",
    "\n",
    "print(\"На оригинальных эмбеддингах\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"На оригинальных эмбеддингах + масштабирование\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, scale=True)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"С использованием PCA\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"pca\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"С использованием PCA + масштабироавние\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"pca\", scale=True)\n",
    "\n",
    "print(\"С использованием SVD\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"svd\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"С использованием SVD + масштабирование\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"svd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая оценка mse - 1.3672444447352596. Она получается на неуменьшенных эмбеддингах и без масштабирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на нейронную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_iter = 10000, чтобы модель могла сойтись\n",
    "model = MLPRegressor(random_state=42, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP:\n",
      "\n",
      "На оригинальных эмбеддингах\n",
      "-1 - 1.4306585077994984\n",
      "\n",
      "С использованием PCA\n",
      "5 - 1.6209707853472843\n",
      "10 - 1.5899125582683968\n",
      "15 - 1.7304625558766156\n",
      "20 - 1.4343316806985988\n",
      "25 - 1.355574255722322\n",
      "50 - 1.1795107218432284\n",
      "100 - 1.2451863619400807\n",
      "200 - 1.6258557722371747\n",
      "-1 - 1.4306585077994984\n",
      "\n",
      "С использованием SVD\n",
      "5 - 1.7439838509920171\n",
      "10 - 1.3618563837699025\n",
      "15 - 1.3834966603108048\n",
      "20 - 1.3019823870974476\n",
      "25 - 1.2812788204710277\n",
      "50 - 1.2165440901652107\n",
      "100 - 1.2729807970806544\n",
      "200 - 1.7428456721093604\n",
      "-1 - 1.4306585077994984\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP:\\n\")\n",
    "\n",
    "print(\"На оригинальных эмбеддингах\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"С использованием PCA\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"pca\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"С использованием SVD\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"svd\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент нейронная сеть с понижением размерности эмбеддинга с помощью PCA до 50 показала наилучшую оценку mse - 1.2237945874117258"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем немного изменить архитектуру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 - 1.218504096837509\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=(300, 150, 25,), random_state=42, max_iter=100000)\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 - 1.771290175695747\n",
      "10 - 1.3437531127799625\n",
      "15 - 1.3746870281778076\n",
      "20 - 1.3648431173606363\n",
      "25 - 1.386822334748024\n",
      "50 - 1.2269312974082418\n",
      "100 - 1.2778318338995986\n",
      "200 - 1.3699219872447168\n",
      "-1 - 1.218504096837509\n"
     ]
    }
   ],
   "source": [
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"pca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При использовании PCA с новой архитектурой мы немного уменьшили mse, но не очень значительно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ячейки выше показывает, что при понижении размерности можно достичь примерно такого же качества, что и при эмбеддинге оригинального размера, но проще ничего не трогать и получать аналогичное качество работы модели или даже выше. Также StandardScaler можно не применять, при его использовании средняя квадратичная ошибка на кросс-валидации слегка увеличивается как на бустинге, так и на линейной модели с регуляризацией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всего себя показала нейронная сеть с понижением размера эмбеддинга. Также можно не понижать размерность эмбеддинга сообщения коммита, но в таком случае необходимо увеличивать количество слоев. Следующими по качеству предсказания идут Ridge и GradientBoostingRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельно проверять tfidf в данный момент уже не буду, так как эмбеддинги предложений, полученные с помощью предобученной модели, сразу показали лучший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('avsoft_test_task')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55b5977c218ce617a475901f98f0c5239dda01575bc0160c4b4058a44613146e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
