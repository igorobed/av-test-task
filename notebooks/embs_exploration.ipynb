{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DungeonMaster3000\\.conda\\envs\\avsoft_test_task\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DungeonMaster3000\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.data_utils as d_u\n",
    "import src.feats_generation as f_g\n",
    "import src.eval_utils as e_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В файле baseline.ipynb было показано, что использование эмбеддинга для сообщения коммита позволяет увеличить точность моделей. Попробуем также tfidf с уменьшением размерности, а также предобученный мультиязыковой кодировщик предложений на основе Transformer и CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет и предобработаем категориальные фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = d_u.get_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_message</th>\n",
       "      <th>bugs</th>\n",
       "      <th>agent</th>\n",
       "      <th>conductor</th>\n",
       "      <th>dockers</th>\n",
       "      <th>mlm</th>\n",
       "      <th>sensor</th>\n",
       "      <th>standard</th>\n",
       "      <th>Alice</th>\n",
       "      <th>Bob</th>\n",
       "      <th>...</th>\n",
       "      <th>Eve</th>\n",
       "      <th>Mallory</th>\n",
       "      <th>Peggy</th>\n",
       "      <th>Trudy</th>\n",
       "      <th>Victor</th>\n",
       "      <th>Wendy</th>\n",
       "      <th>no_work_d</th>\n",
       "      <th>work_d</th>\n",
       "      <th>no_work_h</th>\n",
       "      <th>work_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>added trapconductor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>remove logstash and change data path in filebeat</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Update src/express.py</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       commit_message  bugs  agent  conductor  \\\n",
       "317                               added trapconductor     1      0          0   \n",
       "300  remove logstash and change data path in filebeat     5      0          0   \n",
       "95                              Update src/express.py     1      0          1   \n",
       "\n",
       "     dockers  mlm  sensor  standard  Alice  Bob  ...  Eve  Mallory  Peggy  \\\n",
       "317        0    0       1         0      0    0  ...    0        0      0   \n",
       "300        0    0       1         0      0    0  ...    0        1      0   \n",
       "95         0    0       0         0      0    0  ...    0        0      0   \n",
       "\n",
       "     Trudy  Victor  Wendy  no_work_d  work_d  no_work_h  work_h  \n",
       "317      0       0      0          0       1          0       1  \n",
       "300      0       0      0          0       1          0       1  \n",
       "95       0       0      1          0       1          0       1  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"commit_message\", \"bugs\"])\n",
    "y = df.bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала сразу посмотрим результат модели с эмбеддингами сообщений, которые мы получаем с помощью предобученной мультиязыковой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_embs = f_g.pretrained_model_sentence_emb(df.commit_message.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_idxs, test_idxs = X_train.index, X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, msg_embs[train_idxs]), axis=1)\n",
    "X_test = np.concatenate((X_test, msg_embs[test_idxs]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - LinearRegression()\n",
      "Среднее квадратное отклонение: 3.9255156937438884\n",
      "\n",
      "Модель - SGDRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 1.5442650283714352\n",
      "\n",
      "Модель - Ridge(random_state=42)\n",
      "Среднее квадратное отклонение: 1.3328333886580885\n",
      "\n",
      "Модель - Lasso(random_state=42)\n",
      "Среднее квадратное отклонение: 2.5254327662437523\n",
      "\n",
      "Модель - RandomForestRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 0.86288125\n",
      "\n",
      "Модель - GradientBoostingRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 0.7879865467367375\n",
      "\n",
      "Модель - SVR()\n",
      "Среднее квадратное отклонение: 2.155657021426432\n",
      "\n",
      "Модель - MLPRegressor(max_iter=100000, random_state=42)\n",
      "Среднее квадратное отклонение: 1.7726122043258286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zoo_models = [\n",
    "    LinearRegression(),\n",
    "    SGDRegressor(random_state=42),\n",
    "    Ridge(random_state=42),\n",
    "    Lasso(random_state=42),\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    SVR(),\n",
    "    MLPRegressor(random_state=42, max_iter=100000)\n",
    "    ]\n",
    "\n",
    "for model in zoo_models:\n",
    "    print(f\"Модель - {model}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print(f\"Среднее квадратное отклонение: {mean_squared_error(y_test, preds)}\")\n",
    "    # print(f\"Среднее абсолютное отклонение: {mean_absolute_error(y_test, preds)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу заметно улучшение качества при использовании предобученной модели для генерации эмбеддинга предложения по сравнению с tfidf на том же трэине и тесте(см. baseline.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим среднеквадратическое отклонение на кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - LinearRegression()\n",
      "Среднеквадратическое отклонение: 3.6631705664438847\n",
      "\n",
      "Модель - SGDRegressor(random_state=42)\n",
      "Среднеквадратическое отклонение: 1.5791955326983218\n",
      "\n",
      "Модель - Ridge(random_state=42)\n",
      "Среднеквадратическое отклонение: 1.3792463938249164\n",
      "\n",
      "Модель - Lasso(random_state=42)\n",
      "Среднеквадратическое отклонение: 3.4774931163795175\n",
      "\n",
      "Модель - RandomForestRegressor(random_state=42)\n",
      "Среднеквадратическое отклонение: 1.7560374454365077\n",
      "\n",
      "Модель - GradientBoostingRegressor(random_state=42)\n",
      "Среднеквадратическое отклонение: 1.470161025026534\n",
      "\n",
      "Модель - SVR()\n",
      "Среднеквадратическое отклонение: 2.7170945885316122\n",
      "\n",
      "Модель - MLPRegressor(max_iter=100000, random_state=42)\n",
      "Среднеквадратическое отклонение: 1.4481975235824769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "ss = StandardScaler()\n",
    "X_eval = ss.fit_transform(X)\n",
    "X_eval = np.concatenate((X_eval, msg_embs), axis=1)\n",
    "\n",
    "for model in zoo_models:\n",
    "    print(f\"Модель - {model}\")\n",
    "    mse_mean = -np.mean(cross_val_score(model, X_eval, y, cv=cv, scoring=\"neg_mean_squared_error\"))\n",
    "    print(f\"Среднеквадратическое отклонение: {mse_mean}\")\n",
    "    # preds = model.predict(X_test)\n",
    "    # print(f\"Среднее квадратное отклонение: {mean_squared_error(y_test, preds)}\")\n",
    "    # print(f\"Среднее абсолютное отклонение: {mean_absolute_error(y_test, preds)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от фиксированного трэина и теста на кросс-валидации себя лучше всего показала линейная модель с L2 регуляризацией и однослойная нейронная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим, как понижение размерности эмбеддинга и применение StandardScaler влияет на качество "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала посмотрим на GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На оригинальных эмбеддингах\n",
      "-1 - 1.470161025026534\n",
      "На оригинальных эмбеддингах + масштабирование\n",
      "-1 - 1.470161025026534\n"
     ]
    }
   ],
   "source": [
    "print(\"На оригинальных эмбеддингах\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs)\n",
    "\n",
    "print(\"На оригинальных эмбеддингах + масштабирование\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С использованием PCA\n",
      "5 - 1.5148551894647695\n",
      "10 - 1.4560367799511498\n",
      "15 - 1.4877978299274321\n",
      "20 - 1.5214871692524619\n",
      "25 - 1.482816085116543\n",
      "50 - 1.5609884075840905\n",
      "100 - 1.8245619626528966\n",
      "200 - 1.82374322613191\n",
      "-1 - 1.470161025026534\n"
     ]
    }
   ],
   "source": [
    "print(\"С использованием PCA\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С использованием PCA + масштабироавние\n",
      "5 - 1.489295710440322\n",
      "10 - 1.4538726678656113\n",
      "15 - 1.4751021555784114\n",
      "20 - 1.5180275216073238\n",
      "25 - 1.478111264499026\n",
      "50 - 1.566128901800436\n",
      "100 - 1.7434172615126369\n",
      "200 - 1.817320826978331\n",
      "-1 - 1.470161025026534\n"
     ]
    }
   ],
   "source": [
    "print(\"С использованием PCA + масштабироавние\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"pca\", scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С использованием SVD\n",
      "5 - 1.555566258795838\n",
      "10 - 1.5138571113038022\n",
      "15 - 1.4582576725560403\n",
      "20 - 1.5126696828208244\n",
      "25 - 1.512433820633022\n",
      "50 - 1.590714880944181\n",
      "100 - 1.8915103406943867\n",
      "200 - 1.982722487377621\n",
      "-1 - 1.470161025026534\n",
      "\n",
      "С использованием SVD + масштабирование\n",
      "5 - 1.530622570109774\n",
      "10 - 1.49362152904437\n",
      "15 - 1.46066956586588\n",
      "20 - 1.4773792398921621\n",
      "25 - 1.5572477635659516\n",
      "50 - 1.694677194110767\n",
      "100 - 1.8430409305398765\n",
      "200 - 1.9055306870088375\n",
      "-1 - 1.470161025026534\n"
     ]
    }
   ],
   "source": [
    "print(\"С использованием SVD\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"svd\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"С использованием SVD + масштабирование\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"svd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для базового градиентного бустинга лучший результат - 1.435900249421395 при понижении размерности эмбеддинга с помощью TruncatedSVD до 15 без применения масштабирования. Однако если оставлять исходный размер эмбеддинга, то имеем mse - 1.470161025026534."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь протестируем понижение размерности с моделью Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge:\n",
      "\n",
      "На оригинальных эмбеддингах\n",
      "-1 - 1.3672444447352596\n",
      "\n",
      "На оригинальных эмбеддингах + масштабирование\n",
      "-1 - 1.3791697289464646\n",
      "\n",
      "С использованием PCA\n",
      "5 - 1.608985540104505\n",
      "10 - 1.5056748797877482\n",
      "15 - 1.4955045541755039\n",
      "20 - 1.503601474094973\n",
      "25 - 1.5125714235983743\n",
      "50 - 1.4040745553935343\n",
      "100 - 1.3861526819052499\n",
      "200 - 1.3695839856638639\n",
      "-1 - 1.3672444447352596\n",
      "\n",
      "С использованием PCA + масштабироавние\n",
      "5 - 1.6133605738392085\n",
      "10 - 1.5089069094553893\n",
      "15 - 1.4981613178766167\n",
      "20 - 1.5100405878337801\n",
      "25 - 1.5293546334825607\n",
      "50 - 1.4149903442395846\n",
      "100 - 1.3955291324888093\n",
      "200 - 1.3803108606792143\n",
      "-1 - 1.3791697289464646\n",
      "С использованием SVD\n",
      "5 - 1.715263243857483\n",
      "10 - 1.4772050738427398\n",
      "15 - 1.4645535959873204\n",
      "20 - 1.470583933977404\n",
      "25 - 1.4788954132985617\n",
      "50 - 1.4069166640223916\n",
      "100 - 1.3829728648305806\n",
      "200 - 1.370333452797362\n",
      "-1 - 1.3672444447352596\n",
      "\n",
      "С использованием SVD + масштабирование\n",
      "5 - 1.7145391888961394\n",
      "10 - 1.4737637095027007\n",
      "15 - 1.4610747812439862\n",
      "20 - 1.4712964425881492\n",
      "25 - 1.4795250250973955\n",
      "50 - 1.4079665293558743\n",
      "100 - 1.3857829651313947\n",
      "200 - 1.3708078780104125\n",
      "-1 - 1.3672444447352596\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(random_state=42)\n",
    "\n",
    "print(\"Ridge:\\n\")\n",
    "\n",
    "print(\"На оригинальных эмбеддингах\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"На оригинальных эмбеддингах + масштабирование\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, scale=True)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"С использованием PCA\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"pca\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"С использованием PCA + масштабироавние\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"pca\", scale=True)\n",
    "\n",
    "print(\"С использованием SVD\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"svd\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"С использованием SVD + масштабирование\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"svd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая оценка mse - 1.3672444447352596. Она получается на неуменьшенных эмбеддингах и без масштабирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на нейронную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_iter = 10000, чтобы модель могла сойтись\n",
    "model = MLPRegressor(random_state=42, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP:\n",
      "\n",
      "На оригинальных эмбеддингах\n",
      "-1 - 1.4306585077994984\n",
      "\n",
      "С использованием PCA\n",
      "5 - 1.5748183994232874\n",
      "10 - 1.5974804688051203\n",
      "15 - 1.7617100799757708\n",
      "20 - 1.4290993655345103\n",
      "25 - 1.2983291254581564\n",
      "50 - 1.2237945874117258\n",
      "100 - 1.2416440619267823\n",
      "200 - 1.6417422891675344\n",
      "-1 - 1.4306585077994984\n",
      "\n",
      "С использованием SVD\n",
      "5 - 1.7472114611321974\n",
      "10 - 1.4974275998975868\n",
      "15 - 1.3806399853749596\n",
      "20 - 1.3528996280903498\n",
      "25 - 1.2719689577502364\n",
      "50 - 1.297518674064174\n",
      "100 - 1.2809035338071357\n",
      "200 - 1.7584703650445874\n",
      "-1 - 1.4306585077994984\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP:\\n\")\n",
    "\n",
    "print(\"На оригинальных эмбеддингах\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"С использованием PCA\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"pca\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"С использованием SVD\")\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"svd\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данный момент нейронная сеть с понижением размерности эмбеддинга с помощью PCA до 50 показала наилучшую оценку mse - 1.2237945874117258"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем немного изменить архитектуру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 - 1.218504096837509\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=(300, 150, 25,), random_state=42, max_iter=100000)\n",
    "e_u.eval_emb_reduction(model, X, y, msg_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 - 1.7855156634848783\n",
      "10 - 1.3843189143725183\n",
      "15 - 1.374109487581828\n",
      "20 - 1.3859449720839223\n",
      "25 - 1.3885308917918893\n",
      "50 - 1.1908885605419521\n",
      "100 - 1.2892984050555674\n",
      "200 - 1.3879867785325806\n",
      "-1 - 1.218504096837509\n"
     ]
    }
   ],
   "source": [
    "e_u.eval_emb_reduction(model, X, y, msg_embs, reduct=\"pca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При использовании PCA сновой архитектурой мы немног улучшили mse, но не оч значительно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ячейки выше показывает, что при понижении размерности можно достичь примерн такого же качества, что и при эмбеддингеоригинального размера, но проще ничего не трогать и получать аналогичное качество работы модели или даже выше. Также StandardScaler можно не применять, при его использовании среднеквадратическое отклонение на кросс-валидации слегка увеличивается, как на бустинге, так и на линейной модели с регуляризацией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всего себя показала нейронная сеть с понижением размера эмбеддинга. Также можно не понижать размерность эмбеддинга сообщения коммита, но в таком случае необходимо увеличивать количество слоев. Следующими по качеству предсказания идут Ridge и GradientBoostingRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельно проверять tfidf в данный момент уже не буду, так как эмбеддинги предложений получаемые с помощью предобученной модели сразу показали гораздо лучший результат."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('avsoft_test_task')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55b5977c218ce617a475901f98f0c5239dda01575bc0160c4b4058a44613146e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
