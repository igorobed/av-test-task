{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.data_utils as d_u\n",
    "import src.feats_generation as f_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В файле baseline.ipynb было показано, что использование эмбеддинга для сообщения коммита позволяет увеличить точность моделей. Попробуем также tfidf с уменьшением размерности, а также предобученный мультиязыковой кодировщик предложений на основе Transformer и CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет и предобработаем категориальные фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/АВСОФТ_тест_ML_приложение.csv\")\n",
    "df.drop(columns=[\"commit_hash\"], inplace=True)\n",
    "df = pd.concat([df, pd.get_dummies(df.repository_name)], axis=1)\n",
    "df.drop(columns=[\"repository_name\"], inplace=True)\n",
    "df = f_g.ohe(df, \"commit_author\")\n",
    "df[\"commit_date\"] = pd.to_datetime(df.commit_date)\n",
    "\n",
    "df = f_g.encode_work_days(df)\n",
    "df = f_g.encode_work_hours(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"commit_date\" in df.columns:\n",
    "    df.drop(columns=[\"commit_date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"commit_message\", \"bugs\"])\n",
    "y = df.bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала сразу посмотрим результат модели с эмбеддингами сообщений, которые мы получаем с помощью предобученной мультиязыковой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_embs = model.encode(df.commit_message.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_idxs, test_idxs = X_train.index, X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, msg_embs[train_idxs]), axis=1)\n",
    "X_test = np.concatenate((X_test, msg_embs[test_idxs]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - LinearRegression()\n",
      "Среднее квадратное отклонение: 3.9255156937438884\n",
      "\n",
      "Модель - SGDRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 1.5442650283714352\n",
      "\n",
      "Модель - Ridge(random_state=42)\n",
      "Среднее квадратное отклонение: 1.3328333886580885\n",
      "\n",
      "Модель - Lasso(random_state=42)\n",
      "Среднее квадратное отклонение: 2.5254327662437523\n",
      "\n",
      "Модель - RandomForestRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 0.86288125\n",
      "\n",
      "Модель - GradientBoostingRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 0.7879865467367375\n",
      "\n",
      "Модель - SVR()\n",
      "Среднее квадратное отклонение: 2.155657021426432\n",
      "\n",
      "Модель - MLPRegressor(max_iter=100000, random_state=42)\n",
      "Среднее квадратное отклонение: 1.7726122043258286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zoo_models = [\n",
    "    LinearRegression(),\n",
    "    SGDRegressor(random_state=42),\n",
    "    Ridge(random_state=42),\n",
    "    Lasso(random_state=42),\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    SVR(),\n",
    "    MLPRegressor(random_state=42, max_iter=100000)\n",
    "    ]\n",
    "\n",
    "for model in zoo_models:\n",
    "    print(f\"Модель - {model}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print(f\"Среднее квадратное отклонение: {mean_squared_error(y_test, preds)}\")\n",
    "    # print(f\"Среднее абсолютное отклонение: {mean_absolute_error(y_test, preds)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим среднее квадратичное отклонение на кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - LinearRegression()\n",
      "Среднее квадратное отклонение: 3.6631705664438847\n",
      "\n",
      "Модель - SGDRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 1.5791955326983218\n",
      "\n",
      "Модель - Ridge(random_state=42)\n",
      "Среднее квадратное отклонение: 1.3792463938249164\n",
      "\n",
      "Модель - Lasso(random_state=42)\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "\n",
      "Модель - RandomForestRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 1.7560374454365077\n",
      "\n",
      "Модель - GradientBoostingRegressor(random_state=42)\n",
      "Среднее квадратное отклонение: 1.470161025026534\n",
      "\n",
      "Модель - SVR()\n",
      "Среднее квадратное отклонение: 2.7170945885316122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "ss = StandardScaler()\n",
    "X_eval = ss.fit_transform(X)\n",
    "X_eval = np.concatenate((X_eval, msg_embs), axis=1)\n",
    "\n",
    "for model in zoo_models:\n",
    "    print(f\"Модель - {model}\")\n",
    "    mse_mean = -np.mean(cross_val_score(model, X_eval, y, cv=cv, scoring=\"neg_mean_squared_error\"))\n",
    "    print(f\"Среднее квадратное отклонение: {mse_mean}\")\n",
    "    # preds = model.predict(X_test)\n",
    "    # print(f\"Среднее квадратное отклонение: {mean_squared_error(y_test, preds)}\")\n",
    "    # print(f\"Среднее абсолютное отклонение: {mean_absolute_error(y_test, preds)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_reduction = [TruncatedSVD, PCA]\n",
    "components = [5, 10, 20, 50, 100, 300]\n",
    "dim_red_comps = [(i, j) for i in dim_reduction for j in components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - LinearRegression()\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________5\n",
      "Среднее квадратное отклонение: 1.6746896843097763\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________10\n",
      "Среднее квадратное отклонение: 1.4399618746752116\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________20\n",
      "Среднее квадратное отклонение: 1.4717938529815442\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________50\n",
      "Среднее квадратное отклонение: 1.5749672802220611\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________100\n",
      "Среднее квадратное отклонение: 1.983164210492\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________300\n",
      "Среднее квадратное отклонение: 3.921372149822684\n",
      "<class 'sklearn.decomposition._pca.PCA'>________5\n",
      "Среднее квадратное отклонение: 1.6157300136772275\n",
      "<class 'sklearn.decomposition._pca.PCA'>________10\n",
      "Среднее квадратное отклонение: 1.4822063023231031\n",
      "<class 'sklearn.decomposition._pca.PCA'>________20\n",
      "Среднее квадратное отклонение: 1.5023918637169398\n",
      "<class 'sklearn.decomposition._pca.PCA'>________50\n",
      "Среднее квадратное отклонение: 1.6102188767135233\n",
      "<class 'sklearn.decomposition._pca.PCA'>________100\n",
      "Среднее квадратное отклонение: 1.9501502962589812\n",
      "<class 'sklearn.decomposition._pca.PCA'>________300\n",
      "Среднее квадратное отклонение: 4.521809606427364\n",
      "__________________________________________________\n",
      "Модель - SGDRegressor(random_state=42)\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________5\n",
      "Среднее квадратное отклонение: 1.9149940427290584\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________10\n",
      "Среднее квадратное отклонение: 1.656196404141878\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________20\n",
      "Среднее квадратное отклонение: 1.6507071472626986\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________50\n",
      "Среднее квадратное отклонение: 1.6134229930413864\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________100\n",
      "Среднее квадратное отклонение: 1.5733693243473001\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________300\n",
      "Среднее квадратное отклонение: 1.5791875993071696\n",
      "<class 'sklearn.decomposition._pca.PCA'>________5\n",
      "Среднее квадратное отклонение: 1.7773078071594814\n",
      "<class 'sklearn.decomposition._pca.PCA'>________10\n",
      "Среднее квадратное отклонение: 1.6266877219232103\n",
      "<class 'sklearn.decomposition._pca.PCA'>________20\n",
      "Среднее квадратное отклонение: 1.6305234222855784\n",
      "<class 'sklearn.decomposition._pca.PCA'>________50\n",
      "Среднее квадратное отклонение: 1.5677061932283523\n",
      "<class 'sklearn.decomposition._pca.PCA'>________100\n",
      "Среднее квадратное отклонение: 1.5680708567858628\n",
      "<class 'sklearn.decomposition._pca.PCA'>________300\n",
      "Среднее квадратное отклонение: 1.5442246728415676\n",
      "__________________________________________________\n",
      "Модель - Ridge(random_state=42)\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________5\n",
      "Среднее квадратное отклонение: 1.6635946753702258\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________10\n",
      "Среднее квадратное отклонение: 1.4266277139682377\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________20\n",
      "Среднее квадратное отклонение: 1.4199997417993786\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________50\n",
      "Среднее квадратное отклонение: 1.407586666336003\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________100\n",
      "Среднее квадратное отклонение: 1.3907660053734114\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________300\n",
      "Среднее квадратное отклонение: 1.3792238300954929\n",
      "<class 'sklearn.decomposition._pca.PCA'>________5\n",
      "Среднее квадратное отклонение: 1.6023566085873278\n",
      "<class 'sklearn.decomposition._pca.PCA'>________10\n",
      "Среднее квадратное отклонение: 1.4483886099063916\n",
      "<class 'sklearn.decomposition._pca.PCA'>________20\n",
      "Среднее квадратное отклонение: 1.467990364350102\n",
      "<class 'sklearn.decomposition._pca.PCA'>________50\n",
      "Среднее квадратное отклонение: 1.3973019329518646\n",
      "<class 'sklearn.decomposition._pca.PCA'>________100\n",
      "Среднее квадратное отклонение: 1.3908978557653369\n",
      "<class 'sklearn.decomposition._pca.PCA'>________300\n",
      "Среднее квадратное отклонение: 1.3792155870233107\n",
      "__________________________________________________\n",
      "Модель - Lasso(random_state=42)\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________5\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________10\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________20\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________50\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________100\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________300\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "<class 'sklearn.decomposition._pca.PCA'>________5\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "<class 'sklearn.decomposition._pca.PCA'>________10\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "<class 'sklearn.decomposition._pca.PCA'>________20\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "<class 'sklearn.decomposition._pca.PCA'>________50\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "<class 'sklearn.decomposition._pca.PCA'>________100\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "<class 'sklearn.decomposition._pca.PCA'>________300\n",
      "Среднее квадратное отклонение: 3.4774931163795175\n",
      "__________________________________________________\n",
      "Модель - RandomForestRegressor(random_state=42)\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________5\n",
      "Среднее квадратное отклонение: 1.4860496676587303\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________10\n",
      "Среднее квадратное отклонение: 1.433262609126984\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________20\n",
      "Среднее квадратное отклонение: 1.4899144642857143\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________50\n",
      "Среднее квадратное отклонение: 1.5701762103174606\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________100\n",
      "Среднее квадратное отклонение: 1.7669640277777776\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________300\n",
      "Среднее квадратное отклонение: 1.8899913888888888\n",
      "<class 'sklearn.decomposition._pca.PCA'>________5\n",
      "Среднее квадратное отклонение: 1.6168119345238092\n",
      "<class 'sklearn.decomposition._pca.PCA'>________10\n",
      "Среднее квадратное отклонение: 1.556851646825397\n",
      "<class 'sklearn.decomposition._pca.PCA'>________20\n",
      "Среднее квадратное отклонение: 1.549278814484127\n",
      "<class 'sklearn.decomposition._pca.PCA'>________50\n",
      "Среднее квадратное отклонение: 1.7741598313492066\n",
      "<class 'sklearn.decomposition._pca.PCA'>________100\n",
      "Среднее квадратное отклонение: 1.9638628918650791\n",
      "<class 'sklearn.decomposition._pca.PCA'>________300\n",
      "Среднее квадратное отклонение: 2.1358110367063494\n",
      "__________________________________________________\n",
      "Модель - GradientBoostingRegressor(random_state=42)\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________5\n",
      "Среднее квадратное отклонение: 1.3847539909001993\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________10\n",
      "Среднее квадратное отклонение: 1.4381467762521498\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________20\n",
      "Среднее квадратное отклонение: 1.282733003920434\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________50\n",
      "Среднее квадратное отклонение: 1.3107119136507936\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________100\n",
      "Среднее квадратное отклонение: 1.4390325476576986\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________300\n",
      "Среднее квадратное отклонение: 1.6175758248410812\n",
      "<class 'sklearn.decomposition._pca.PCA'>________5\n",
      "Среднее квадратное отклонение: 1.560198055756087\n",
      "<class 'sklearn.decomposition._pca.PCA'>________10\n",
      "Среднее квадратное отклонение: 1.485065881231964\n",
      "<class 'sklearn.decomposition._pca.PCA'>________20\n",
      "Среднее квадратное отклонение: 1.543583044814832\n",
      "<class 'sklearn.decomposition._pca.PCA'>________50\n",
      "Среднее квадратное отклонение: 1.580915765058553\n",
      "<class 'sklearn.decomposition._pca.PCA'>________100\n",
      "Среднее квадратное отклонение: 1.786326086020883\n",
      "<class 'sklearn.decomposition._pca.PCA'>________300\n",
      "Среднее квадратное отклонение: 1.863869911861256\n",
      "__________________________________________________\n",
      "Модель - SVR()\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________5\n",
      "Среднее квадратное отклонение: 2.753149476569699\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________10\n",
      "Среднее квадратное отклонение: 2.7101066003923213\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________20\n",
      "Среднее квадратное отклонение: 2.706323987747833\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________50\n",
      "Среднее квадратное отклонение: 2.714163770813855\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________100\n",
      "Среднее квадратное отклонение: 2.7146264478492625\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>________300\n",
      "Среднее квадратное отклонение: 2.717111530878539\n",
      "<class 'sklearn.decomposition._pca.PCA'>________5\n",
      "Среднее квадратное отклонение: 2.7309952432491\n",
      "<class 'sklearn.decomposition._pca.PCA'>________10\n",
      "Среднее квадратное отклонение: 2.710781293209989\n",
      "<class 'sklearn.decomposition._pca.PCA'>________20\n",
      "Среднее квадратное отклонение: 2.709808782172914\n",
      "<class 'sklearn.decomposition._pca.PCA'>________50\n",
      "Среднее квадратное отклонение: 2.7115929193144153\n",
      "<class 'sklearn.decomposition._pca.PCA'>________100\n",
      "Среднее квадратное отклонение: 2.714194274297379\n",
      "<class 'sklearn.decomposition._pca.PCA'>________300\n",
      "Среднее квадратное отклонение: 2.716730762676369\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for model in zoo_models:\n",
    "    print(f\"Модель - {model}\")\n",
    "    for red, comp in dim_red_comps:\n",
    "        print(f\"{red}________{comp}\")\n",
    "        ss = StandardScaler()\n",
    "        X_eval = ss.fit_transform(X)\n",
    "        red_embs = red(n_components=comp).fit_transform(msg_embs)\n",
    "        X_eval = np.concatenate((X_eval, red_embs), axis=1)\n",
    "        mse_mean = -np.mean(cross_val_score(model, X_eval, y, cv=cv, scoring=\"neg_mean_squared_error\"))\n",
    "        print(f\"Среднее квадратное отклонение: {mse_mean}\")\n",
    "    print(\"__________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данный момент можно сделать вывод, что лучший результат достигается при снижении размерности эмбеддинга получаемого предварительно обученной моделью с помощью TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем подобрать наиболее подходящую итоговую размерность эмбеддинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>conductor</th>\n",
       "      <th>dockers</th>\n",
       "      <th>mlm</th>\n",
       "      <th>sensor</th>\n",
       "      <th>standard</th>\n",
       "      <th>Alice</th>\n",
       "      <th>Bob</th>\n",
       "      <th>Carol</th>\n",
       "      <th>Dabe</th>\n",
       "      <th>Eve</th>\n",
       "      <th>Mallory</th>\n",
       "      <th>Peggy</th>\n",
       "      <th>Trudy</th>\n",
       "      <th>Victor</th>\n",
       "      <th>Wendy</th>\n",
       "      <th>no_work_d</th>\n",
       "      <th>work_d</th>\n",
       "      <th>no_work_h</th>\n",
       "      <th>work_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     agent  conductor  dockers  mlm  sensor  standard  Alice  Bob  Carol  \\\n",
       "0        0          0        0    1       0         0      0    0      0   \n",
       "1        0          0        0    1       0         0      0    0      0   \n",
       "2        0          0        0    1       0         0      0    0      0   \n",
       "3        0          0        0    1       0         0      0    0      0   \n",
       "4        0          0        0    1       0         0      0    0      0   \n",
       "..     ...        ...      ...  ...     ...       ...    ...  ...    ...   \n",
       "314      0          0        0    0       1         0      0    0      0   \n",
       "315      0          0        0    0       1         0      0    0      0   \n",
       "316      0          0        0    0       1         0      0    0      0   \n",
       "317      0          0        0    0       1         0      0    0      0   \n",
       "318      0          0        0    0       1         0      0    0      0   \n",
       "\n",
       "     Dabe  Eve  Mallory  Peggy  Trudy  Victor  Wendy  no_work_d  work_d  \\\n",
       "0       0    0        0      0      0       1      0          0       1   \n",
       "1       0    0        0      0      0       1      0          0       1   \n",
       "2       0    0        0      0      0       1      0          0       1   \n",
       "3       0    0        0      0      0       1      0          0       1   \n",
       "4       0    0        0      0      0       1      0          0       1   \n",
       "..    ...  ...      ...    ...    ...     ...    ...        ...     ...   \n",
       "314     1    0        0      0      0       0      0          0       1   \n",
       "315     1    0        0      0      0       0      0          0       1   \n",
       "316     1    0        0      0      0       0      0          0       1   \n",
       "317     1    0        0      0      0       0      0          0       1   \n",
       "318     1    0        0      0      0       0      0          0       1   \n",
       "\n",
       "     no_work_h  work_h  \n",
       "0            0       1  \n",
       "1            0       1  \n",
       "2            0       1  \n",
       "3            0       1  \n",
       "4            0       1  \n",
       "..         ...     ...  \n",
       "314          0       1  \n",
       "315          0       1  \n",
       "316          0       1  \n",
       "317          0       1  \n",
       "318          0       1  \n",
       "\n",
       "[319 rows x 20 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 - 1.818188605536184\n",
      "10 - 1.3885376721725884\n",
      "15 - 1.243824744753063\n",
      "20 - 1.1993175413434083\n",
      "25 - 1.2646591428309857\n",
      "30 - 1.2581325392105236\n",
      "40 - 1.209634622731476\n",
      "50 - 1.1949957423631052\n",
      "100 - 1.2411780621861077\n",
      "200 - 1.3845428980240941\n",
      "250 - 1.4015651592658023\n",
      "-1 - 1.218504096837509\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model = MLPRegressor(hidden_layer_sizes=(300, 150, 25,), random_state=42, max_iter=100000)\n",
    "\n",
    "for n in [5, 10, 15, 20, 25, 30, 40, 50, 100, 200, 250, -1]:\n",
    "    splits = cv.split(X)\n",
    "    tmp_lst = []\n",
    "    for i_train, i_test in splits:\n",
    "        if n != -1:\n",
    "            svd = TruncatedSVD(n_components=n)\n",
    "            msg_embs_train = svd.fit_transform(msg_embs[i_train])\n",
    "            msg_embs_test = svd.transform(msg_embs[i_test])\n",
    "        else:\n",
    "            msg_embs_train = msg_embs[i_train]\n",
    "            msg_embs_test = msg_embs[i_test]\n",
    "        X_train, X_test, y_train, y_test = X.loc[i_train], X.loc[i_test], y[i_train], y[i_test]\n",
    "        # ss = StandardScaler()\n",
    "        # X_train = ss.fit_transform(X_train)\n",
    "        # X_test = ss.transform(X_test)\n",
    "        X_train_emb = np.concatenate((X_train, msg_embs_train), axis=1)\n",
    "        X_test_emb = np.concatenate((X_test, msg_embs_test), axis=1)\n",
    "        model.fit(X_train_emb, y_train)\n",
    "        preds = model.predict(X_test_emb)\n",
    "        tmp_lst.append(mean_squared_error(y_test, preds))\n",
    "    print(f\"{n} - {np.mean(tmp_lst)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ячейки выше показывает, что при понижении размерности можно достичь примерн такого же качества, что и при эмбеддингеоригинального размера, но проще ничего не трогать и получать аналогичное качество работы модели или даже выше. Также StandardScaler так же можно не применять, при его использовании среднее квадратичное отклонение на кросс-валидации слегка увеличивается, как на бустинге, так и на линейной модели с регуляризацией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всего себя показала нейронная сеть с понижением размера эмбеддинга. Также можно не понижать размерность эмбеддинга сообщения коммита, но в таком случае необходимо увеличивать количество слоев. Следующими по качеству предсказания идут Ridge и GradientBoostingRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельно проверять tfidf в данный момент уже не буду, так как эмбеддинги предложений получаемые с помощью предобученной модели сразу показали гораздо лучший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ('avsoft_test_task')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
