{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DungeonMaster3000\\.conda\\envs\\avsoft_test_task\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DungeonMaster3000\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import src.data_utils as d_u\n",
    "import src.feats_generation as f_g\n",
    "import src.eval_utils as e_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала с помощью подбора гиперпараметров посмотрим, какое наилучшее решение мы можем получить, используя линейную регрессию с L2 регуляризацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получим предобработанный датасет\n",
    "\n",
    "df = d_u.get_preprocess_data()\n",
    "\n",
    "X = df.drop(columns=[\"commit_message\", \"bugs\"])\n",
    "y = df.bugs\n",
    "\n",
    "msg_embs = f_g.pretrained_model_sentence_emb(df.commit_message.values)\n",
    "\n",
    "X = np.concatenate((X.to_numpy(), msg_embs), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# конфигурация для поиска наилучшего решения\n",
    "\n",
    "ridge_config = {\n",
    "    \"alpha\": [0.5, 1.0, 1.5, 5.0, 10],\n",
    "    \"solver\": [\"auto\", \"svd\", \"cholesky\", \"sag\"],\n",
    "    \"random_state\": [42],\n",
    "    \"tol\": [1e-2, 1e-3, 1e-4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "model_ridge = Ridge(random_state=42)\n",
    "gs_ridge = GridSearchCV(model_ridge, ridge_config, cv=cv, scoring=\"neg_mean_squared_error\", verbose=1)\n",
    "search = gs_ridge.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.5, 'random_state': 42, 'solver': 'sag', 'tol': 0.01}\n",
      "-1.3645594120400553\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на лучшие параметры и лучшую оценку\n",
    "\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее качество для линейной модели с L2 регуляризацией - 1.3645594120400553"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь поперебираем параметры для нейронной сети из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_config = {\n",
    "    \"hidden_layer_sizes\": [(100,), (300, 100,), (300, 100, 50)],\n",
    "    \"activation\": [\"logistic\", \"tanh\", \"relu\"],\n",
    "    \"solver\": [\"sgd\", \"adam\"],\n",
    "    \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    \"random_state\": [42],\n",
    "    \"max_iter\": [10000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "model_nn = MLPRegressor(random_state=42)\n",
    "gs_nn = GridSearchCV(model_nn, nn_config, cv=cv, scoring=\"neg_mean_squared_error\", verbose=1)\n",
    "search = gs_nn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'hidden_layer_sizes': (300, 100), 'learning_rate': 'constant', 'max_iter': 10000, 'random_state': 42, 'solver': 'sgd'}\n",
      "-1.0978673099828316\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на лучшие параметры и лучшую оценку\n",
    "\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее качество для нейронной сети - 1.0978673099828316"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем подобрать параметры для градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_config = {\n",
    "    \"loss\": [\"squared_error\", \"absolute_error\", \"huber\"],\n",
    "    \"learning_rate\": [0.1, 0.5, 1.0],\n",
    "    \"n_estimators\": [100, 150, 200],\n",
    "    \"criterion\": [\"squared_error\"],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"random_state\": [42]    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "model_gb = GradientBoostingRegressor(random_state=42)\n",
    "gs_gb = GridSearchCV(model_gb, gb_config, cv=cv, scoring=\"neg_mean_squared_error\", verbose=2)\n",
    "search = gs_gb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'squared_error', 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'n_estimators': 150, 'random_state': 42}\n",
      "-1.4590573214275597\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на лучшие параметры и лучшую оценку\n",
    "\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг дает качество на даннной задаче значительно хуже нежели Ridge и MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем специализированную библиотеку для градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7115090825707544\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "model_lgb = LGBMRegressor(random_state=42)\n",
    "# gs_gb = GridSearchCV(model_gb, gb_config, cv=cv, scoring=\"neg_mean_squared_error\", verbose=2)\n",
    "# search = gs_gb.fit(X, y)\n",
    "print(np.mean(cross_val_score(model_lgb, X, y, cv=cv, scoring=\"neg_mean_squared_error\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4879989582292803\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "model_cgb = CatBoostRegressor(random_state=42, verbose=0)\n",
    "# gs_gb = GridSearchCV(model_gb, gb_config, cv=cv, scoring=\"neg_mean_squared_error\", verbose=2)\n",
    "# search = gs_gb.fit(X, y)\n",
    "print(np.mean(cross_val_score(model_cgb, X, y, cv=cv, scoring=\"neg_mean_squared_error\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У базового регрессора из catboost качество получилось близкое к качеству модели градиентного бустинга из sklearn с параметрами подобранными по сетке. Попробуем применить его без предобработки категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/АВСОФТ_тест_ML_приложение.csv\")\n",
    "df.drop(columns=[\"commit_hash\"], inplace=True)\n",
    "\n",
    "df[\"commit_date\"] = pd.to_datetime(df.commit_date)\n",
    "\n",
    "df = f_g.encode_work_days(df)\n",
    "df = f_g.encode_work_hours(df)\n",
    "\n",
    "if \"commit_date\" in df.columns:\n",
    "    df.drop(columns=[\"commit_date\"], inplace=True)\n",
    "\n",
    "X = df.drop(columns=[\"commit_message\", \"bugs\"])\n",
    "y = df.bugs\n",
    "\n",
    "msg_embs = f_g.pretrained_model_sentence_emb(df.commit_message.values)\n",
    "\n",
    "X = pd.concat((X, pd.DataFrame(msg_embs)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repository_name</th>\n",
       "      <th>commit_author</th>\n",
       "      <th>no_work_d</th>\n",
       "      <th>work_d</th>\n",
       "      <th>no_work_h</th>\n",
       "      <th>work_h</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>conductor</td>\n",
       "      <td>Dabe</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.079920</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>0.019246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016541</td>\n",
       "      <td>-0.001993</td>\n",
       "      <td>-0.009228</td>\n",
       "      <td>-0.052684</td>\n",
       "      <td>0.048641</td>\n",
       "      <td>-0.010819</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.034769</td>\n",
       "      <td>-0.063120</td>\n",
       "      <td>0.067844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>sensor</td>\n",
       "      <td>Victor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.082101</td>\n",
       "      <td>-0.019746</td>\n",
       "      <td>-0.009664</td>\n",
       "      <td>-0.031541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005454</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.029946</td>\n",
       "      <td>0.054653</td>\n",
       "      <td>-0.026029</td>\n",
       "      <td>-0.033068</td>\n",
       "      <td>-0.016885</td>\n",
       "      <td>0.029324</td>\n",
       "      <td>0.092721</td>\n",
       "      <td>-0.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>conductor</td>\n",
       "      <td>Wendy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.015878</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>-0.052344</td>\n",
       "      <td>-0.023136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>-0.017067</td>\n",
       "      <td>0.018917</td>\n",
       "      <td>0.030094</td>\n",
       "      <td>-0.020613</td>\n",
       "      <td>0.013868</td>\n",
       "      <td>-0.038820</td>\n",
       "      <td>-0.006034</td>\n",
       "      <td>0.010248</td>\n",
       "      <td>0.006112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    repository_name commit_author  no_work_d  work_d  no_work_h  work_h  \\\n",
       "178       conductor          Dabe          0       1          0       1   \n",
       "258          sensor        Victor          0       1          1       0   \n",
       "85        conductor         Wendy          0       1          0       1   \n",
       "\n",
       "            0         1         2         3  ...       502       503  \\\n",
       "178  0.016709  0.079920  0.003142  0.019246  ...  0.016541 -0.001993   \n",
       "258 -0.082101 -0.019746 -0.009664 -0.031541  ... -0.005454  0.005846   \n",
       "85  -0.015878  0.002328 -0.052344 -0.023136  ...  0.012363 -0.017067   \n",
       "\n",
       "          504       505       506       507       508       509       510  \\\n",
       "178 -0.009228 -0.052684  0.048641 -0.010819  0.015667  0.034769 -0.063120   \n",
       "258  0.029946  0.054653 -0.026029 -0.033068 -0.016885  0.029324  0.092721   \n",
       "85   0.018917  0.030094 -0.020613  0.013868 -0.038820 -0.006034  0.010248   \n",
       "\n",
       "          511  \n",
       "178  0.067844  \n",
       "258 -0.108200  \n",
       "85   0.006112  \n",
       "\n",
       "[3 rows x 518 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "model_cgb = CatBoostRegressor(random_state=42, verbose=0, cat_features=[\"repository_name\", \"commit_author\"])\n",
    "# gs_gb = GridSearchCV(model_gb, gb_config, cv=cv, scoring=\"neg_mean_squared_error\", verbose=2)\n",
    "# search = gs_gb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.609263768264578\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(cross_val_score(model_cgb, X, y, cv=cv, scoring=\"neg_mean_squared_error\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вряд ли подбор параметров позволит приблизиться к лидеру(нейронная сеть), однако в дальнейшем стоит поэксперементировать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшим подходом в данный момент себя показало кодирование имени репозитория, а также деление на 3 группы по числу найденных ошибок авторов комммитов и кодирование их также с помощью One-Hot Encoder. Также была подтверждена гипотеза, что учитывая смысл(хотя бы частичный) сообщения коммита можно лучше предсказывать число найденных багов. Время коммита было преобразованно в пару полезных признаков: рабочее или не рабочее время и рабочий или выходной день недели. Я испробовал TfidfVectorizer и предобученную мультиязычную модель на основе Transformer и CNN для получения эмбеддинга предложения. Второй вариант дал гораздо более сильное уменьшение среднеквадратического отклонения. Также были испробованы TruncatedSVD и PCA, так как данных оч мало, а размер получаемого вектора признаков для объекта превышает общее количество объектов в имеющемся датасете. Однако, данные подходы не показали сколько-нибудь значительного улучшения качества работы модели.\n",
    "\n",
    "Лучше всего себя на данный момент показала двухслойная нейронная сеть с функцийе активации Relu. Ее mse на кросс-валидации составило 1.0978673099828316. \n",
    "\n",
    "Дальнейшая работа:\n",
    "\n",
    "1. Обучить двух(трех)слойную нейронную сеть с помощью фрэймворка Pytorch с использованием слоя Embeddings для категориальных переменных имя репозитория, имя автора коммита, рабочее время, рабочий день недели.\n",
    "\n",
    "2. Попробовать применить стэкинг\n",
    "\n",
    "3. Подумать над тем, какие еще признаки можн сгенерировать вручную на основе времени коммита и текста сообщения коммита.\n",
    "\n",
    "4. Попробовать поподбирать параметры для моделей из специализированных библиотек для градиентного бустинга(lightgbm и catboost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('avsoft_test_task')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55b5977c218ce617a475901f98f0c5239dda01575bc0160c4b4058a44613146e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
